version: '3.1'

services:
#  python:
#    image: python/pyspark-notebook 
#    container_name: python 
#    hostname: python
#    restart: always
#    ports:
#       - "8888:8888"
#    container_name: python
#    hostname: python
#    networks:
#      net:
#        ipv4_address: 171.69.1.1
#    restart: always

  python:
    image: python:3.6-alpine
    container_name: python
    hostname: python
    restart: always
    networks:
      net:
        ipv4_address: 171.69.1.1
    command: ["tail", "-f", "/dev/null"]
    restart: always

  mongo:
    image: mongo:4.0.5-xenial
    container_name: mongo
    hostname: mongo
    restart: always
    depends_on: 
      - python
      - spark
    environment:
      MONGO_INITDB_ROOT_USERNAME: root
      MONGO_INITDB_ROOT_PASSWORD: example
    networks:
      net:
        ipv4_address: 171.69.1.2
    volumes: 
      - ./mongo/data/:/data/db/
    #command: >
     # bash -c "mongod && sleep 30 && mongoimport --host=127.0.0.1 --jsonArray -u root -p 'example' --authenticationDatabase admin -d movies -c american_movies /data/db/movies.json"

  mongo-express:
    image: mongo-express:0.49
    container_name: mongo-express
    hostname: mongo-express
    restart: always
    ports:
      - 8081:8081
    environment:
      ME_CONFIG_MONGODB_ADMINUSERNAME: root
      ME_CONFIG_MONGODB_ADMINPASSWORD: example
    networks:
      net:
        ipv4_address: 171.69.1.3

  mysql:
    image: danspaes/mysql-with-data
    container_name: mysql
    hostname: mysql
    restart: always
    depends_on:
      - python
      - spark
    environment:
      MYSQL_ROOT_USER: root
      MYSQL_ROOT_PASSWORD: example
      PMA_HOST: mysql
    command:
      - "--default-authentication-plugin=mysql_native_password"

  redis:
    image: redis:5.0.3
    container_name: redis
    hostname: redis
    restart: always
    ports: 
      - "6379:6379"
    depends_on: 
      - python
      - spark
    networks:
      net:
        ipv4_address: 171.69.1.4
    volumes: 
      - ./redis/data:/data
    command: ["redis-server", "--appendonly", "yes"] 

  cassandra:
    image: cassandra:3.11
    container_name: cassandra
    hostname: cassandra
    restart: always
    depends_on: 
      - python
      - spark
    networks:
      net:
        ipv4_address: 171.69.1.5
    volumes: 
      - ./cassandra/data:/var/lib/cassandra/

  neo4j:
    image: neo4j:3.5.3
    container_name: neo4j
    hostname: neo4j
    restart: always
    ports: 
      - "7474:7474"
      - "7687:7687"
    depends_on: 
      - python
      - spark
    environment:
      NEO4J_AUTH: none
    networks:
      net:
        ipv4_address: 171.69.1.6
    volumes: 
      - ./neo4j/data:/var/lib/neo4j/data/databases/

  spark:
    image: danspaes/spark-slim
    container_name: spark
    hostname: spark
    environment:
      - "SPARK_MASTER_PORT=7077"
      - "SPARK_MASTER_WEBUI_PORT=8080"
    command: spark-class org.apache.spark.deploy.master.Master
    networks:
      net:
        ipv4_address: 171.69.1.7
    depends_on: 
      - kafka 
    ports: 
      - "4040:4040"
      - "7077:7077"
      - "8080:8080"
      - "6066:6066"

    expose: 
      - "4040"
      - "7077"
      - "8080"
      - "6066"
    #volumes: 
     # - ./consumer:/opt/consumer
     # - ./data:/tmp/data

  spark_worker:
    image: danspaes/spark-slim
    container_name: spark_worker
    depends_on:
      - spark
    command: spark-class org.apache.spark.deploy.worker.Worker spark://171.69.1.3:7077
    ports:
      - "8081:8081"
    environment:
      - "SPARK_CONF_DIR=/conf"
      - "SPARK_WORKER_CORES=3"
      - "SPARK_WORKER_MEMORY=300m"
      - "SPARK_WORKER_PORT=8881"
      - "SPARK_WORKER_WEBUI_PORT=8081"
    extra_hosts:
      - "spark:171.69.1.7"
    ports: 
      - "8081"
    networks:
      net:
    volumes:
      - ./data:/tmp/data

  kafka:
    image: spotify/kafka
    ports:
      - "9092:9092"
      - "2181:2181"
    container_name: kafka
    hostname: kafka
    networks:
      net:
        ipv4_address: 171.69.1.8
    expose:
      - "9092"
      - "2181"
    environment:
      ADVERTISED_HOST: 171.69.1.8
      ADVERTISED_PORT: 9092
      AUTO_CREATE_TOPICS: "false" 
      DELETE_TOPIC_ENABLE: "true" 
    command: >
      bash -c
      "(sleep 15s &&
      /opt/kafka_2.11-0.10.1.0/bin/kafka-topics.sh
      --create
      --zookeeper
      localhost:2181 --replication-factor 1 --partitions 1
      --topic stocks &) && (supervisord -n)"
    
    restart: always

networks:
    net:
        ipam:
            driver: default
            config:
                - subnet: 171.69.0.0/16
